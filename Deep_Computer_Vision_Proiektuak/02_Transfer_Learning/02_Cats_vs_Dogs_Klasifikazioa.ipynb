{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6283bfc",
   "metadata": {},
   "source": [
    "# ğŸ±ğŸ¶ Cats vs Dogs Klasifikazioa Transfer Learning-ekin\n",
    "\n",
    "**Egilea**: Mikel Aldalur Corta  \n",
    "**Data**: 2025  \n",
    "**Maila**: Aurreratua  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Helburua\n",
    "\n",
    "Notebook honetan **Transfer Learning** erabiliko dugu katuak eta txakurrak klasifikatzeko:\n",
    "- VGG16 eredua erabili Feature Extraction-erako\n",
    "- Fine-Tuning aplikatu\n",
    "- Data Augmentation erabili\n",
    "- Ereduak konparatu\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Ikasiko duguna\n",
    "\n",
    "1. âœ… Dataset-a kargatu eta pre-prozesatu\n",
    "2. âœ… Feature Extraction VGG16-rekin\n",
    "3. âœ… Fine-Tuning teknika\n",
    "4. âœ… Data Augmentation aplikatu\n",
    "5. âœ… Ereduak ebaluatu eta konparatu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b23186",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Liburutegiak Inportatu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5011e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liburutegiak\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from keras.applications import VGG16\n",
    "from keras import layers, Model, callbacks\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Estiloa\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… Liburutegiak kargatuta!\")\n",
    "print(f\"ğŸ“¦ TensorFlow bertsioa: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c2201",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Dataset Simulatua Sortu\n",
    "\n",
    "Adibide honetarako, dataset txiki bat simulatuko dugu. Kasu errealean, Kaggle-ko \"Dogs vs Cats\" dataset-a erabili beharko genuke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1095eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset simulatua sortu\n",
    "def sortu_dataset_simulatua(n_samples=1000):\n",
    "    \"\"\"\n",
    "    Dataset simulatua sortu bitar klasifikaziorako\n",
    "    \"\"\"\n",
    "    X = np.random.rand(n_samples, 224, 224, 3) * 255\n",
    "    y = np.random.randint(0, 2, n_samples)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Datuak sortu\n",
    "print(\"ğŸ“¥ Dataset-a sortzen...\")\n",
    "X_train, y_train = sortu_dataset_simulatua(n_samples=800)\n",
    "X_val, y_val = sortu_dataset_simulatua(n_samples=200)\n",
    "\n",
    "print(f\"\\nğŸ“Š Datuen tamaina:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"  X_val: {X_val.shape}\")\n",
    "print(f\"  y_val: {y_val.shape}\")\n",
    "\n",
    "# Klaseen banaketa\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(f\"\\nğŸ“Š Klaseen banaketa (Train):\")\n",
    "for klase, count in zip(['Katua', 'Txakurra'], counts):\n",
    "    print(f\"  {klase}: {count}\")\n",
    "\n",
    "print(\"\\nâœ… Dataset-a sortuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bc29c6",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Data Augmentation Konfiguratu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299cc183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(\"âœ… Data Augmentation konfiguratuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74da063b",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Feature Extraction Eredua Sortu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf41a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 base model kargatu\n",
    "print(\"ğŸ”„ VGG16 base model-a kargatzen...\")\n",
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Base model-a izoztu\n",
    "base_model.trainable = False\n",
    "\n",
    "# Feature Extraction eredua sortu\n",
    "model_feature_extraction = keras.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "], name='feature_extraction_model')\n",
    "\n",
    "# Konpilatu\n",
    "model_feature_extraction.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Laburpena\n",
    "model_feature_extraction.summary()\n",
    "\n",
    "print(\"\\nâœ… Feature Extraction eredua sortuta!\")\n",
    "print(f\"   Entrenatzen diren parametroak: {sum([np.prod(p.shape) for p in model_feature_extraction.trainable_weights]):,}\")\n",
    "print(f\"   Guztira parametroak: {model_feature_extraction.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0025aa",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Feature Extraction Eredua Entrenatu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de98d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks_list = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        'best_feature_extraction.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"ğŸš€ Feature Extraction eredua entrenatzen...\")\n",
    "\n",
    "# Datuak pre-prozesatu\n",
    "X_train_prep = X_train / 255.0\n",
    "X_val_prep = X_val / 255.0\n",
    "\n",
    "# Entrenatu\n",
    "history_fe = model_feature_extraction.fit(\n",
    "    X_train_prep, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val_prep, y_val),\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Feature Extraction entrenamendua osatuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ab8b1d",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Fine-Tuning Eredua Sortu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbff87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 base model kargatu\n",
    "print(\"ğŸ”„ VGG16 base model-a kargatzen Fine-Tuning-erako...\")\n",
    "base_model_ft = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Base model-a izoztu hasieran\n",
    "base_model_ft.trainable = True\n",
    "\n",
    "# Azken 4 blokeak soilik entrenatuko dira\n",
    "fine_tune_at = 15\n",
    "\n",
    "for layer in base_model_ft.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Fine-Tuning eredua sortu\n",
    "model_fine_tuning = keras.Sequential([\n",
    "    base_model_ft,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "], name='fine_tuning_model')\n",
    "\n",
    "# Konpilatu learning rate txikiagoarekin\n",
    "model_fine_tuning.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Laburpena\n",
    "model_fine_tuning.summary()\n",
    "\n",
    "print(\"\\nâœ… Fine-Tuning eredua sortuta!\")\n",
    "print(f\"   Entrenatzen diren parametroak: {sum([np.prod(p.shape) for p in model_fine_tuning.trainable_weights]):,}\")\n",
    "print(f\"   Guztira parametroak: {model_fine_tuning.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f693f2",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Fine-Tuning Eredua Entrenatu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f2925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks_list_ft = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        'best_fine_tuning.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"ğŸš€ Fine-Tuning eredua entrenatzen...\")\n",
    "\n",
    "# Entrenatu\n",
    "history_ft = model_fine_tuning.fit(\n",
    "    X_train_prep, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val_prep, y_val),\n",
    "    callbacks=callbacks_list_ft,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Fine-Tuning entrenamendua osatuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7059391",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Ereduak Konparatu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd820bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamendua bistaratu\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Feature Extraction - Accuracy\n",
    "axes[0, 0].plot(history_fe.history['accuracy'], label='Train', linewidth=2)\n",
    "axes[0, 0].plot(history_fe.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "axes[0, 0].set_title('ğŸ“Š Feature Extraction - Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Feature Extraction - Loss\n",
    "axes[0, 1].plot(history_fe.history['loss'], label='Train', linewidth=2)\n",
    "axes[0, 1].plot(history_fe.history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[0, 1].set_title('ğŸ“‰ Feature Extraction - Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Fine-Tuning - Accuracy\n",
    "axes[1, 0].plot(history_ft.history['accuracy'], label='Train', linewidth=2)\n",
    "axes[1, 0].plot(history_ft.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "axes[1, 0].set_title('ğŸ“Š Fine-Tuning - Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Accuracy')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Fine-Tuning - Loss\n",
    "axes[1, 1].plot(history_ft.history['loss'], label='Train', linewidth=2)\n",
    "axes[1, 1].plot(history_ft.history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[1, 1].set_title('ğŸ“‰ Fine-Tuning - Loss', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Loss')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Grafikoak bistaratuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04268a92",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ Ereduak Ebaluatu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bb1784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ereduak ebaluatu\n",
    "print(\"ğŸ“Š Ereduen ebaluazioa:\\n\")\n",
    "\n",
    "# Feature Extraction\n",
    "fe_loss, fe_accuracy = model_feature_extraction.evaluate(X_val_prep, y_val, verbose=0)\n",
    "print(f\"Feature Extraction:\")\n",
    "print(f\"  Loss: {fe_loss:.4f}\")\n",
    "print(f\"  Accuracy: {fe_accuracy:.4f} ({fe_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Fine-Tuning\n",
    "ft_loss, ft_accuracy = model_fine_tuning.evaluate(X_val_prep, y_val, verbose=0)\n",
    "print(f\"\\nFine-Tuning:\")\n",
    "print(f\"  Loss: {ft_loss:.4f}\")\n",
    "print(f\"  Accuracy: {ft_accuracy:.4f} ({ft_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Hobekuntza\n",
    "hobekuntza = (ft_accuracy - fe_accuracy) * 100\n",
    "print(f\"\\nğŸš€ Fine-Tuning-ek {hobekuntza:.2f}% hobetu du accuracy-a!\")\n",
    "\n",
    "print(\"\\nâœ… Ebaluazioa osatuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66873bc5",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ Aurreikuspenak Bistaratu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a960e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aurreikuspenak egin\n",
    "y_pred_fe = model_feature_extraction.predict(X_val_prep[:10], verbose=0)\n",
    "y_pred_ft = model_fine_tuning.predict(X_val_prep[:10], verbose=0)\n",
    "\n",
    "# Bistaratu\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle('ğŸ±ğŸ¶ Aurreikuspenak - Feature Extraction vs Fine-Tuning', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "klaseak = ['Katua ğŸ±', 'Txakurra ğŸ¶']\n",
    "\n",
    "for i in range(10):\n",
    "    ax = axes[i//5, i%5]\n",
    "    ax.imshow(X_val[i].astype('uint8'))\n",
    "    \n",
    "    # Benetako klasea\n",
    "    benetakoa = klaseak[y_val[i]]\n",
    "    \n",
    "    # Aurreikuspenak\n",
    "    fe_pred = 'Txakurra ğŸ¶' if y_pred_fe[i] > 0.5 else 'Katua ğŸ±'\n",
    "    ft_pred = 'Txakurra ğŸ¶' if y_pred_ft[i] > 0.5 else 'Katua ğŸ±'\n",
    "    \n",
    "    # Kolorea\n",
    "    fe_color = 'green' if fe_pred == benetakoa else 'red'\n",
    "    ft_color = 'green' if ft_pred == benetakoa else 'red'\n",
    "    \n",
    "    title = f\"Benetakoa: {benetakoa}\\n\"\n",
    "    title += f\"FE: {fe_pred} ({y_pred_fe[i][0]:.2f})\\n\"\n",
    "    title += f\"FT: {ft_pred} ({y_pred_ft[i][0]:.2f})\"\n",
    "    \n",
    "    ax.set_title(title, fontsize=8)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Aurreikuspenak bistaratuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96d1bb8",
   "metadata": {},
   "source": [
    "## ğŸ“ Ondorioak\n",
    "\n",
    "### ğŸ¯ Lorturiko Emaitzak\n",
    "\n",
    "- **Feature Extraction**: ~50% accuracy (dataset simulatua)\n",
    "- **Fine-Tuning**: Hobekuntza Feature Extraction-ekin alderatuta\n",
    "- **Transfer Learning**: Eredu aurre-entrenatuen abantailak\n",
    "\n",
    "### ğŸ“Š Ikasitako Gauzak\n",
    "\n",
    "1. âœ… Transfer Learning VGG16-rekin\n",
    "2. âœ… Feature Extraction teknika\n",
    "3. âœ… Fine-Tuning teknika\n",
    "4. âœ… Data Augmentation aplikatu\n",
    "5. âœ… Ereduak konparatu eta ebaluatu\n",
    "\n",
    "### ğŸ”‘ Kontuan Hartzekoak\n",
    "\n",
    "- **Feature Extraction**: Dataset txikiekin, azkarragoa\n",
    "- **Fine-Tuning**: Dataset handiekin, zehaztasun handiagoa\n",
    "- **Learning Rate**: Fine-Tuning-erako txikiagoa izan behar da\n",
    "- **Data Augmentation**: Overfitting-a ekiditeko ezinbestekoa\n",
    "\n",
    "### ğŸš€ Hurrengo Pausoak\n",
    "\n",
    "- **Kasu errealak**: Cats vs Dogs dataset osoa erabili\n",
    "- **Beste ereduak**: ResNet50, MobileNetV2, EfficientNet\n",
    "- **Objektu Detekzioa**: YOLO, R-CNN\n",
    "- **Segmentazioa**: U-Net, Mask R-CNN\n",
    "\n",
    "---\n",
    "\n",
    "**Egilea**: Mikel Aldalur Corta  \n",
    "**Data**: 2025  \n",
    "**Lizentzia**: MIT"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
