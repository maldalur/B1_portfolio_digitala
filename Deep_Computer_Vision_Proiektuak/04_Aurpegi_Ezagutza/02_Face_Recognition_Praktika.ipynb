{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35057395",
   "metadata": {},
   "source": [
    "# üë• Face Recognition Praktika - dlib eta face_recognition\n",
    "\n",
    "**Egilea**: Mikel Aldalur Corta  \n",
    "**Data**: 2025  \n",
    "**Maila**: Aurreratua  \n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Helburua\n",
    "\n",
    "Notebook honetan **Face Recognition praktika** egingo dugu Python liburutegiak erabiliz:\n",
    "- face_recognition liburutegia (dlib-en wrapper)\n",
    "- Aurpegiak detektatu\n",
    "- Face encodings sortu\n",
    "- Aurpegiak konparatu eta identifikatu\n",
    "- Webcam-etik real-time recognition\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Ikasiko duguna\n",
    "\n",
    "1. ‚úÖ face_recognition liburutegia instalatu eta erabili\n",
    "2. ‚úÖ Aurpegiak detektatu irudian\n",
    "3. ‚úÖ Face landmarks aurkitu\n",
    "4. ‚úÖ Face encodings (128D) sortu\n",
    "5. ‚úÖ Aurpegiak konparatu eta identifikatu\n",
    "6. ‚úÖ Real-time recognition (kontzeptua)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc03ad25",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Instalazioa\n",
    "\n",
    "### üì¶ Behar diren liburutegiak\n",
    "\n",
    "```bash\n",
    "# dlib instalatu (beharrezkoa)\n",
    "pip install dlib\n",
    "\n",
    "# face_recognition instalatu\n",
    "pip install face_recognition\n",
    "\n",
    "# OpenCV (bideoak prozesatzeko)\n",
    "pip install opencv-python\n",
    "\n",
    "# Pillow (irudiak prozesatzeko)\n",
    "pip install Pillow\n",
    "```\n",
    "\n",
    "### ‚ö†Ô∏è Oharra\n",
    "\n",
    "- **Windows**: dlib instalatzea korapilatsua izan daiteke. CMake eta Visual Studio C++ behar ditu.\n",
    "- **Linux/Mac**: Errazagoa da.\n",
    "- **Alternatiba**: Docker erabiliz edo Google Colab-en exekutatu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ab1291",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Liburutegiak Inportatu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d174736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liburutegiak\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Estiloa\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Liburutegiak oinarrizkoak kargatuta!\")\n",
    "\n",
    "# face_recognition probatu\n",
    "try:\n",
    "    import face_recognition\n",
    "    print(\"‚úÖ face_recognition liburutegia erabilgarri!\")\n",
    "    print(f\"   Bertsioa: {face_recognition.__version__ if hasattr(face_recognition, '__version__') else 'Ezezaguna'}\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è face_recognition ez dago instalatuta.\")\n",
    "    print(\"   Instala ezazu: pip install face_recognition\")\n",
    "    face_recognition = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aec7e51",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Face Detection Simulazioa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b959e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detection simulazioa\n",
    "def simulatu_face_detection():\n",
    "    \"\"\"\n",
    "    Face detection emaitza simulatu\n",
    "    \"\"\"\n",
    "    # Irudi simulatua sortu\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    \n",
    "    img = np.random.rand(500, 600, 3) * 0.3 + 0.4\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Aurpegi-kokalekuak simulatu\n",
    "    aurpegiak = [\n",
    "        (100, 100, 150, 200),  # (top, right, bottom, left)\n",
    "        (300, 150, 400, 250),\n",
    "        (150, 400, 250, 500)\n",
    "    ]\n",
    "    \n",
    "    for i, (top, right, bottom, left) in enumerate(aurpegiak, 1):\n",
    "        # Bounding box marraztu\n",
    "        width = right - left\n",
    "        height = bottom - top\n",
    "        rect = patches.Rectangle(\n",
    "            (left, top), width, height,\n",
    "            linewidth=2, edgecolor='lime', facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Label\n",
    "        ax.text(left, top-10, f'Aurpegia {i}',\n",
    "               bbox=dict(facecolor='lime', alpha=0.7),\n",
    "               fontsize=11, color='black', fontweight='bold')\n",
    "    \n",
    "    ax.set_title('üë§ Face Detection Simulazioa', \n",
    "                fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ {len(aurpegiak)} aurpegi detektatuta!\")\n",
    "\n",
    "simulatu_face_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ecdca3",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Face Detection Kodea (Erreala)\n",
    "\n",
    "```python\n",
    "import face_recognition\n",
    "\n",
    "# Irudia kargatu\n",
    "image = face_recognition.load_image_file(\"path/to/image.jpg\")\n",
    "\n",
    "# Aurpegiak detektatu\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "print(f\"Detektatutako aurpegiak: {len(face_locations)}\")\n",
    "\n",
    "# Bakoitza marraztu\n",
    "for (top, right, bottom, left) in face_locations:\n",
    "    print(f\"Aurpegi bat: Top={top}, Right={right}, Bottom={bottom}, Left={left}\")\n",
    "```\n",
    "\n",
    "### üìä Detekzio Metodoak\n",
    "\n",
    "```python\n",
    "# HOG metodoa (azkarragoa, defektua)\n",
    "face_locations = face_recognition.face_locations(image, model=\"hog\")\n",
    "\n",
    "# CNN metodoa (zehatza, motela, GPU behar)\n",
    "face_locations = face_recognition.face_locations(image, model=\"cnn\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7872d7e8",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Face Landmarks\n",
    "\n",
    "**Face Landmarks**: Aurpegiaren puntu garrantzitsuak (begiak, sudurra, ahoa, etab.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24db92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face landmarks simulazioa\n",
    "def simulatu_face_landmarks():\n",
    "    \"\"\"\n",
    "    Face landmarks simulazioa\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 10))\n",
    "    \n",
    "    # Aurpegi-forma oinarrizkoa\n",
    "    img = np.ones((400, 300, 3)) * 0.9\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Landmark puntuak simulatu\n",
    "    landmarks = {\n",
    "        'chin': [(150 + i*3, 50 + i*20) for i in range(17)],\n",
    "        'left_eyebrow': [(80 + i*10, 120 - i*2) for i in range(5)],\n",
    "        'right_eyebrow': [(170 + i*10, 120 - (4-i)*2) for i in range(5)],\n",
    "        'left_eye': [(90, 150), (100, 145), (110, 145), (120, 150), (110, 155), (100, 155)],\n",
    "        'right_eye': [(180, 150), (190, 145), (200, 145), (210, 150), (200, 155), (190, 155)],\n",
    "        'nose': [(150, 180), (145, 200), (150, 210), (155, 200)],\n",
    "        'top_lip': [(110, 250), (130, 245), (150, 240), (170, 245), (190, 250)],\n",
    "        'bottom_lip': [(190, 250), (170, 260), (150, 265), (130, 260), (110, 250)]\n",
    "    }\n",
    "    \n",
    "    koloreak = {\n",
    "        'chin': 'blue',\n",
    "        'left_eyebrow': 'red',\n",
    "        'right_eyebrow': 'red',\n",
    "        'left_eye': 'green',\n",
    "        'right_eye': 'green',\n",
    "        'nose': 'orange',\n",
    "        'top_lip': 'purple',\n",
    "        'bottom_lip': 'purple'\n",
    "    }\n",
    "    \n",
    "    for part_name, points in landmarks.items():\n",
    "        xs = [p[0] for p in points]\n",
    "        ys = [p[1] for p in points]\n",
    "        ax.plot(xs, ys, 'o-', color=koloreak[part_name], \n",
    "               linewidth=2, markersize=6, label=part_name)\n",
    "    \n",
    "    ax.set_title('üéØ Face Landmarks (68 puntos)', \n",
    "                fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='upper right', fontsize=9)\n",
    "    ax.axis('off')\n",
    "    ax.set_xlim([50, 250])\n",
    "    ax.set_ylim([350, 50])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "simulatu_face_landmarks()\n",
    "print(\"‚úÖ Face landmarks (68 puntu) bistaratuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7758c3",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Face Landmarks Kodea (Erreala)\n",
    "\n",
    "```python\n",
    "import face_recognition\n",
    "\n",
    "# Irudia kargatu\n",
    "image = face_recognition.load_image_file(\"path/to/image.jpg\")\n",
    "\n",
    "# Face landmarks lortu\n",
    "face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "\n",
    "for face_landmarks in face_landmarks_list:\n",
    "    for facial_feature in face_landmarks.keys():\n",
    "        print(f\"{facial_feature}: {len(face_landmarks[facial_feature])} puntos\")\n",
    "```\n",
    "\n",
    "### üìä Landmark Aplikazioak\n",
    "\n",
    "- **Face Alignment**: Aurpegiak lerrokatu\n",
    "- **Emotion Recognition**: Emozioak detektatu\n",
    "- **Face Filters**: Snapchat-en antzeko filtroak\n",
    "- **Makeup**: Makillaje birtuala aplikatu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dde2348",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Face Encodings (128D)\n",
    "\n",
    "Face encoding-a **128 dimensioko bektore** bat da aurpegiaren ezaugarriak adierazten dituena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c3e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face encodings simulazioa\n",
    "def simulatu_face_encodings():\n",
    "    \"\"\"\n",
    "    Face encodings simulazioa\n",
    "    \"\"\"\n",
    "    # 3 pertsonaren encodings simulatuak\n",
    "    mikel_encoding = np.random.randn(128)\n",
    "    ane_encoding = np.random.randn(128)\n",
    "    jon_encoding = np.random.randn(128)\n",
    "    \n",
    "    # Mikel-en beste argazki bat (antzekoa izan behar du)\n",
    "    mikel_encoding_2 = mikel_encoding + np.random.randn(128) * 0.1\n",
    "    \n",
    "    print(\"üß† Face Encodings (128D):\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Mikel encoding:   [{mikel_encoding[0]:.3f}, {mikel_encoding[1]:.3f}, {mikel_encoding[2]:.3f}, ...]\")\n",
    "    print(f\"Ane encoding:     [{ane_encoding[0]:.3f}, {ane_encoding[1]:.3f}, {ane_encoding[2]:.3f}, ...]\")\n",
    "    print(f\"Jon encoding:     [{jon_encoding[0]:.3f}, {jon_encoding[1]:.3f}, {jon_encoding[2]:.3f}, ...]\")\n",
    "    print(f\"Mikel encoding 2: [{mikel_encoding_2[0]:.3f}, {mikel_encoding_2[1]:.3f}, {mikel_encoding_2[2]:.3f}, ...]\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Distantziak kalkulatu\n",
    "    dist_mikel_mikel = np.linalg.norm(mikel_encoding - mikel_encoding_2)\n",
    "    dist_mikel_ane = np.linalg.norm(mikel_encoding - ane_encoding)\n",
    "    dist_mikel_jon = np.linalg.norm(mikel_encoding - jon_encoding)\n",
    "    \n",
    "    print(\"\\nüìè Distantziak:\")\n",
    "    print(f\"  Mikel vs Mikel (aurpegi bera): {dist_mikel_mikel:.4f}\")\n",
    "    print(f\"  Mikel vs Ane (desberdina):     {dist_mikel_ane:.4f}\")\n",
    "    print(f\"  Mikel vs Jon (desberdina):     {dist_mikel_jon:.4f}\")\n",
    "    \n",
    "    # Bistaratu\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    \n",
    "    labels = ['Mikel vs Mikel\\n(aurpegi bera)', 'Mikel vs Ane\\n(desberdina)', 'Mikel vs Jon\\n(desberdina)']\n",
    "    distantziak = [dist_mikel_mikel, dist_mikel_ane, dist_mikel_jon]\n",
    "    colors = ['green', 'red', 'red']\n",
    "    \n",
    "    bars = ax.bar(labels, distantziak, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "    ax.axhline(y=0.6, color='blue', linestyle='--', linewidth=2, label='Threshold (0.6)')\n",
    "    ax.set_ylabel('Distantzia Euklidarra', fontsize=12)\n",
    "    ax.set_title('üìè Face Encodings - Distantzien Konparaketa', \n",
    "                fontsize=16, fontweight='bold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Balioak gehitu\n",
    "    for bar, dist in zip(bars, distantziak):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "               f'{dist:.4f}',\n",
    "               ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "simulatu_face_encodings()\n",
    "print(\"\\n‚úÖ Face encodings simulazioa osatuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770fe041",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Face Encodings Kodea (Erreala)\n",
    "\n",
    "```python\n",
    "import face_recognition\n",
    "\n",
    "# Irudiak kargatu\n",
    "mikel_image = face_recognition.load_image_file(\"mikel.jpg\")\n",
    "ane_image = face_recognition.load_image_file(\"ane.jpg\")\n",
    "\n",
    "# Encodings sortu\n",
    "mikel_encoding = face_recognition.face_encodings(mikel_image)[0]\n",
    "ane_encoding = face_recognition.face_encodings(ane_image)[0]\n",
    "\n",
    "print(f\"Mikel encoding: {mikel_encoding.shape}\")  # (128,)\n",
    "print(f\"Ane encoding: {ane_encoding.shape}\")      # (128,)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ff289e",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Face Comparison eta Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38a5c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face comparison simulazioa\n",
    "def simulatu_face_comparison():\n",
    "    \"\"\"\n",
    "    Face comparison eta recognition simulazioa\n",
    "    \"\"\"\n",
    "    # Datu-baseko encodings\n",
    "    database = {\n",
    "        'Mikel': np.random.randn(128),\n",
    "        'Ane': np.random.randn(128),\n",
    "        'Jon': np.random.randn(128),\n",
    "        'Leire': np.random.randn(128)\n",
    "    }\n",
    "    \n",
    "    # Test encodings\n",
    "    test_cases = [\n",
    "        ('Mikel argazki berria', database['Mikel'] + np.random.randn(128) * 0.1, 'Mikel'),\n",
    "        ('Ane argazki berria', database['Ane'] + np.random.randn(128) * 0.15, 'Ane'),\n",
    "        ('Ezezagun bat', np.random.randn(128), 'Ezezaguna')\n",
    "    ]\n",
    "    \n",
    "    threshold = 0.6\n",
    "    \n",
    "    print(\"üîç Face Recognition Simulazioa:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for test_name, test_encoding, expected in test_cases:\n",
    "        print(f\"\\nüì∏ Test: {test_name}\")\n",
    "        print(f\"   Espero: {expected}\")\n",
    "        \n",
    "        # Datu-baseko pertsona guztiekin konparatu\n",
    "        distantziak = {}\n",
    "        for izena, encoding in database.items():\n",
    "            dist = np.linalg.norm(test_encoding - encoding)\n",
    "            distantziak[izena] = dist\n",
    "        \n",
    "        # Hurbilena aurkitu\n",
    "        hurbilena = min(distantziak, key=distantziak.get)\n",
    "        dist_min = distantziak[hurbilena]\n",
    "        \n",
    "        # Identifikatu\n",
    "        if dist_min < threshold:\n",
    "            identifikatua = hurbilena\n",
    "            status = \"‚úÖ\"\n",
    "        else:\n",
    "            identifikatua = \"Ezezaguna\"\n",
    "            status = \"‚ùå\"\n",
    "        \n",
    "        print(f\"   Emaitza: {identifikatua} (distantzia: {dist_min:.4f})\")\n",
    "        print(f\"   {status} {'Zuzena!' if identifikatua == expected else 'Okerra!'}\")\n",
    "        \n",
    "        # Distantzia guztiak\n",
    "        print(f\"   Distantziak:\")\n",
    "        for izena, dist in sorted(distantziak.items(), key=lambda x: x[1]):\n",
    "            print(f\"      - {izena}: {dist:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "simulatu_face_comparison()\n",
    "print(\"‚úÖ Face comparison simulazioa osatuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31f94a3",
   "metadata": {},
   "source": [
    "## üîü Face Recognition Kodea Osoa (Erreala)\n",
    "\n",
    "```python\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "\n",
    "# 1. Datu-basea sortu (ezagunak)\n",
    "mikel_image = face_recognition.load_image_file(\"mikel.jpg\")\n",
    "ane_image = face_recognition.load_image_file(\"ane.jpg\")\n",
    "\n",
    "mikel_encoding = face_recognition.face_encodings(mikel_image)[0]\n",
    "ane_encoding = face_recognition.face_encodings(ane_image)[0]\n",
    "\n",
    "known_encodings = [mikel_encoding, ane_encoding]\n",
    "known_names = [\"Mikel\", \"Ane\"]\n",
    "\n",
    "# 2. Test irudia\n",
    "test_image = face_recognition.load_image_file(\"test.jpg\")\n",
    "test_encoding = face_recognition.face_encodings(test_image)[0]\n",
    "\n",
    "# 3. Konparatu\n",
    "matches = face_recognition.compare_faces(known_encodings, test_encoding)\n",
    "name = \"Ezezaguna\"\n",
    "\n",
    "# Distantziak kalkulatu\n",
    "face_distances = face_recognition.face_distance(known_encodings, test_encoding)\n",
    "best_match_index = np.argmin(face_distances)\n",
    "\n",
    "if matches[best_match_index]:\n",
    "    name = known_names[best_match_index]\n",
    "\n",
    "print(f\"Aurpegia identifikatuta: {name}\")\n",
    "print(f\"Distantzia: {face_distances[best_match_index]:.4f}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c3ae4",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Webcam Real-Time Recognition (Kontzeptua)\n",
    "\n",
    "```python\n",
    "import face_recognition\n",
    "import cv2\n",
    "\n",
    "# Webcam ireki\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Datu-basea kargatu\n",
    "known_encodings = [mikel_encoding, ane_encoding]\n",
    "known_names = [\"Mikel\", \"Ane\"]\n",
    "\n",
    "while True:\n",
    "    # Frame bat irakurri\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    # BGR -> RGB\n",
    "    rgb_frame = frame[:, :, ::-1]\n",
    "    \n",
    "    # Aurpegiak detektatu eta encodings lortu\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "    \n",
    "    # Aurpegi bakoitza identifikatu\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding)\n",
    "        name = \"Ezezaguna\"\n",
    "        \n",
    "        face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        \n",
    "        if matches[best_match_index]:\n",
    "            name = known_names[best_match_index]\n",
    "        \n",
    "        # Marraztu\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                   0.75, (0, 255, 0), 2)\n",
    "    \n",
    "    # Bistaratu\n",
    "    cv2.imshow('Face Recognition', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cb9072",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Performance Optimizazioak\n",
    "\n",
    "### ‚ö° Optimizazio Aholkuak\n",
    "\n",
    "1. **Frame-ak saltatu**: Ez prozesatu frame guztiak\n",
    "```python\n",
    "frame_count = 0\n",
    "process_every = 5  # Prozesatu 5. frame-a bakarrik\n",
    "\n",
    "if frame_count % process_every == 0:\n",
    "    # Prozesatu frame-a\n",
    "    pass\n",
    "frame_count += 1\n",
    "```\n",
    "\n",
    "2. **Tamaina txikitu**: Frame-ak txikitu prozesatzeko\n",
    "```python\n",
    "small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "```\n",
    "\n",
    "3. **HOG vs CNN**: HOG azkarra, CNN zehatza\n",
    "```python\n",
    "# Azkarragoa\n",
    "face_locations = face_recognition.face_locations(frame, model=\"hog\")\n",
    "\n",
    "# Zehatza baina motela\n",
    "face_locations = face_recognition.face_locations(frame, model=\"cnn\")\n",
    "```\n",
    "\n",
    "4. **GPU**: dlib-ek GPU euskarria du\n",
    "```python\n",
    "import dlib\n",
    "dlib.DLIB_USE_CUDA = True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67afd551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance konparaketa simulazioa\n",
    "def simulatu_performance():\n",
    "    \"\"\"\n",
    "    Metodo desberdinen performance simulazioa\n",
    "    \"\"\"\n",
    "    metodoak = ['HOG (CPU)', 'CNN (CPU)', 'CNN (GPU)']\n",
    "    fps = [30, 5, 25]\n",
    "    zehaztasuna = [0.95, 0.99, 0.99]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    fig.suptitle('üìä Face Recognition Performance Konparaketa', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # FPS\n",
    "    colors_fps = ['green', 'red', 'orange']\n",
    "    bars1 = axes[0].bar(metodoak, fps, color=colors_fps, alpha=0.7, \n",
    "                       edgecolor='black', linewidth=2)\n",
    "    axes[0].set_ylabel('FPS (Frames per second)', fontsize=12)\n",
    "    axes[0].set_title('‚ö° Abiadura', fontsize=14, fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Balioak\n",
    "    for bar, val in zip(bars1, fps):\n",
    "        height = bar.get_height()\n",
    "        axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{val} FPS',\n",
    "                   ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Zehaztasuna\n",
    "    colors_acc = ['orange', 'green', 'green']\n",
    "    bars2 = axes[1].bar(metodoak, zehaztasuna, color=colors_acc, alpha=0.7, \n",
    "                       edgecolor='black', linewidth=2)\n",
    "    axes[1].set_ylabel('Zehaztasuna', fontsize=12)\n",
    "    axes[1].set_title('üéØ Zehaztasuna', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_ylim([0.9, 1.0])\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Balioak\n",
    "    for bar, val in zip(bars2, zehaztasuna):\n",
    "        height = bar.get_height()\n",
    "        axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{val:.2%}',\n",
    "                   ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.tick_params(axis='x', rotation=15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "simulatu_performance()\n",
    "print(\"‚úÖ Performance konparaketa bistaratuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311e3936",
   "metadata": {},
   "source": [
    "## üìù Ondorioak\n",
    "\n",
    "### üéØ Ikasitako Gauzak\n",
    "\n",
    "1. ‚úÖ face_recognition liburutegia erabili\n",
    "2. ‚úÖ Aurpegiak detektatu (HOG, CNN)\n",
    "3. ‚úÖ Face landmarks (68 puntu) aurkitu\n",
    "4. ‚úÖ Face encodings (128D) sortu\n",
    "5. ‚úÖ Aurpegiak konparatu eta identifikatu\n",
    "6. ‚úÖ Real-time recognition implementatu (kontzeptua)\n",
    "\n",
    "### üìä face_recognition Liburutegiaren Abantailak\n",
    "\n",
    "- ‚úÖ **Erraza**: API oso sinplea\n",
    "- ‚úÖ **Zehatza**: dlib-en gainean eraikita (99.38% zehaztasuna)\n",
    "- ‚úÖ **Osoa**: Detection, landmarks, encoding, comparison\n",
    "- ‚úÖ **Dokumentazioa**: Oso ondo dokumentatuta\n",
    "\n",
    "### üîë Aplikazio Erabilgarriak\n",
    "\n",
    "1. **Segurtasuna**: Sarrera-kontrola, autentifikazioa\n",
    "2. **Asistentzia**: Langile/ikasle asistentzia kontrola\n",
    "3. **Sare sozialak**: Auto-tagging (argazkietan pertsonak etiketatu)\n",
    "4. **Smart Home**: Etxeko automatizazioa\n",
    "5. **Bilaketa**: Argazki datu-basean pertsonak bilatu\n",
    "\n",
    "### ‚ö†Ô∏è Etikako Kontuak\n",
    "\n",
    "- **Pribatutasuna**: Datu pertsonalak babestea (GDPR)\n",
    "- **Baimena**: Beti eskatu baimena\n",
    "- **Bias**: Arrazaren, generoaren, adinaren sesgoak\n",
    "- **Transparentzia**: Erabiltzaileei jakinarazi\n",
    "- **Erabilera**: Ez diskriminazio-erabileretarako\n",
    "\n",
    "### üöÄ Hurrengo Pausoak\n",
    "\n",
    "- **Custom dataset**: Gure pertsonak identifikatzeko sistema\n",
    "- **Database**: SQL/MongoDB datu-basea integratu\n",
    "- **Web app**: Flask/FastAPI aplikazio bat sortu\n",
    "- **Mobile**: React Native edo Flutter app-a\n",
    "- **Cloud**: AWS Rekognition, Azure Face API\n",
    "\n",
    "---\n",
    "\n",
    "**Egilea**: Mikel Aldalur Corta  \n",
    "**Data**: 2025  \n",
    "**Lizentzia**: MIT"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
