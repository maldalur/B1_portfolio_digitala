{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7795cfb9",
   "metadata": {},
   "source": [
    "# üë§ Aurpegi Ezagutza - Face Detection eta Recognition\n",
    "\n",
    "**Egilea**: Mikel Aldalur Corta  \n",
    "**Data**: 2025  \n",
    "**Maila**: Aurreratua  \n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Helburua\n",
    "\n",
    "Notebook honetan **Aurpegi Ezagutza** (Face Recognition) ikasiko dugu:\n",
    "- Face Detection vs Face Recognition\n",
    "- Aurpegi detekzioa (HOG, CNN)\n",
    "- Face embeddings\n",
    "- Aurpegi ezagutza praktika\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Ikasiko duguna\n",
    "\n",
    "1. ‚úÖ Face Detection oinarriak\n",
    "2. ‚úÖ Face Recognition oinarriak\n",
    "3. ‚úÖ Face Embeddings\n",
    "4. ‚úÖ Face Verification vs Identification\n",
    "5. ‚úÖ Praktika kasu errealak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41df115",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Face Detection vs Face Recognition\n",
    "\n",
    "### üîç Face Detection\n",
    "\n",
    "**Face Detection**: Irudian aurpegiak aurkitzea eta lokalizatzea\n",
    "\n",
    "- Input: Irudia\n",
    "- Output: Bounding boxes aurpegien inguruan\n",
    "\n",
    "### üéØ Face Recognition\n",
    "\n",
    "**Face Recognition**: Aurpegia nor den identifikatzea\n",
    "\n",
    "- Input: Aurpegiaren irudia\n",
    "- Output: Nortasuna\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Pipeline-a\n",
    "\n",
    "```\n",
    "Irudia ‚Üí Face Detection ‚Üí Face Alignment ‚Üí Face Recognition ‚Üí Identitatea\n",
    "```\n",
    "\n",
    "1. **Face Detection**: Aurpegia detektatu\n",
    "2. **Face Alignment**: Aurpegia normalizatu (begiak, sudurra, ahoa lerrokatu)\n",
    "3. **Face Encoding**: Aurpegia embedding bihurtu (128D bektorea)\n",
    "4. **Face Recognition**: Embedding-a datu-basearekin konparatu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d5bd42",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Liburutegiak Inportatu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d177eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liburutegiak\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageDraw\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Estiloa\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Liburutegiak kargatuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e82d1e",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Face Detection Teknikak\n",
    "\n",
    "### 1. **Haar Cascades** (Klasikoa)\n",
    "\n",
    "- Viola-Jones algoritmoa (2001)\n",
    "- Haar-like features erabiltzen ditu\n",
    "- Oso azkarra baina ez hain zehatza\n",
    "\n",
    "### 2. **HOG (Histogram of Oriented Gradients)**\n",
    "\n",
    "- Face landmarks detektatzeko\n",
    "- HOG features + Linear SVM\n",
    "- Ondo funtzionatzen du\n",
    "\n",
    "### 3. **CNN-based** (Modernoa)\n",
    "\n",
    "- MTCNN, RetinaFace, etc.\n",
    "- Zehaztasun handia\n",
    "- Pixka bat motela\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Konparaketa\n",
    "\n",
    "| Teknika | Abiadura | Zehaztasuna | Erabilera |\n",
    "|---------|----------|-------------|-----------|\n",
    "| **Haar Cascades** | Oso azkarra | Baxua | Legacy aplikazioak |\n",
    "| **HOG** | Azkarra | Ona | Desktop aplikazioak |\n",
    "| **CNN** | Motela | Oso ona | Zehaztasun kritikoa |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c7a029",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Face Detection Simulazioa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3d70d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detection simulazioa\n",
    "def simulatu_face_detection():\n",
    "    \"\"\"\n",
    "    Face detection simulazioa irudi batean\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    \n",
    "    # Irudi simulatua\n",
    "    img = np.random.rand(400, 600, 3) * 0.3 + 0.3\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Aurpegi simulatuak\n",
    "    aurpegiak = [\n",
    "        ((50, 50, 80, 100), 'Persona 1', 0.98),\n",
    "        ((200, 100, 70, 90), 'Persona 2', 0.95),\n",
    "        ((400, 150, 75, 95), 'Persona 3', 0.92),\n",
    "        ((100, 250, 80, 100), 'Persona 4', 0.89)\n",
    "    ]\n",
    "    \n",
    "    for (x, y, w, h), label, conf in aurpegiak:\n",
    "        # Bounding box\n",
    "        from matplotlib.patches import Rectangle\n",
    "        rect = Rectangle((x, y), w, h, \n",
    "                        linewidth=2, edgecolor='lime', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Label\n",
    "        ax.text(x, y-5, f'{label} ({conf:.2f})',\n",
    "               bbox=dict(facecolor='lime', alpha=0.7),\n",
    "               fontsize=10, color='black', fontweight='bold')\n",
    "    \n",
    "    ax.set_title('üë§ Face Detection Simulazioa', \n",
    "                fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "simulatu_face_detection()\n",
    "print(\"‚úÖ Face detection simulazioa bistaratuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1ded22",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Face Embeddings\n",
    "\n",
    "**Face Embeddings**: Aurpegiaren bektore-errepresentazio bat (normalean 128D edo 512D)\n",
    "\n",
    "### üîë Nola sortzen da?\n",
    "\n",
    "1. **CNN eredua**: FaceNet, DeepFace, ArcFace\n",
    "2. **Triplet Loss**: Aurpegi beraren embeddings hurbil, desberdinak urrun\n",
    "3. **Output**: 128D bektorea\n",
    "\n",
    "---\n",
    "\n",
    "### üìê Triplet Loss\n",
    "\n",
    "$$\n",
    "L = \\max(0, ||f(a) - f(p)||^2 - ||f(a) - f(n)||^2 + \\alpha)\n",
    "$$\n",
    "\n",
    "- **a**: Anchor (oinarria)\n",
    "- **p**: Positive (aurpegi bera)\n",
    "- **n**: Negative (aurpegi desberdina)\n",
    "- **Œ±**: Margin (adibidez, 0.2)\n",
    "\n",
    "**Helburua**: $||f(a) - f(p)|| < ||f(a) - f(n)||$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fb258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face embeddings simulazioa\n",
    "def simulatu_face_embeddings():\n",
    "    \"\"\"\n",
    "    Face embeddings simulazioa 3D-an\n",
    "    \"\"\"\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    \n",
    "    # Aurpegi embeddings simulatuak (3D, bistan izateko)\n",
    "    # Errealitatean 128D edo 512D izango lirateke\n",
    "    \n",
    "    # Persona 1 aurpegiak (hurbil)\n",
    "    persona1 = np.random.randn(10, 3) * 0.3 + np.array([1, 1, 1])\n",
    "    \n",
    "    # Persona 2 aurpegiak (hurbil)\n",
    "    persona2 = np.random.randn(10, 3) * 0.3 + np.array([4, 4, 1])\n",
    "    \n",
    "    # Persona 3 aurpegiak (hurbil)\n",
    "    persona3 = np.random.randn(10, 3) * 0.3 + np.array([2, 5, 5])\n",
    "    \n",
    "    # Bistaratu\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    ax.scatter(persona1[:, 0], persona1[:, 1], persona1[:, 2], \n",
    "              c='red', s=100, marker='o', label='Persona 1', alpha=0.6)\n",
    "    ax.scatter(persona2[:, 0], persona2[:, 1], persona2[:, 2], \n",
    "              c='blue', s=100, marker='^', label='Persona 2', alpha=0.6)\n",
    "    ax.scatter(persona3[:, 0], persona3[:, 1], persona3[:, 2], \n",
    "              c='green', s=100, marker='s', label='Persona 3', alpha=0.6)\n",
    "    \n",
    "    ax.set_xlabel('Embedding Dim 1', fontsize=12)\n",
    "    ax.set_ylabel('Embedding Dim 2', fontsize=12)\n",
    "    ax.set_zlabel('Embedding Dim 3', fontsize=12)\n",
    "    ax.set_title('üß† Face Embeddings 3D Simulazioa', \n",
    "                fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.legend(fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "simulatu_face_embeddings()\n",
    "print(\"‚úÖ Face embeddings simulazioa bistaratuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086940e7",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Face Verification vs Face Identification\n",
    "\n",
    "### üîê Face Verification (1:1)\n",
    "\n",
    "**Galdera**: Aurpegi hau eta hau pertsona bera da?\n",
    "\n",
    "- Input: 2 aurpegi\n",
    "- Output: Bai/Ez\n",
    "\n",
    "**Metodoa**:\n",
    "1. Bi aurpegien embeddings kalkulatu\n",
    "2. Distantzia kalkulatu (Euclidean, Cosine)\n",
    "3. Threshold-arekin konparatu\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Face Identification (1:N)\n",
    "\n",
    "**Galdera**: Aurpegi hau nor da datu-basean?\n",
    "\n",
    "- Input: Aurpegi bat\n",
    "- Output: Identitatea (edo \"Ezezaguna\")\n",
    "\n",
    "**Metodoa**:\n",
    "1. Aurpegiaren embedding kalkulatu\n",
    "2. Datu-baseko embedding guztiekin konparatu\n",
    "3. Hurbilena aukeratu (threshold-tik azpian bada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f24c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face verification adibidea\n",
    "def face_verification_simulazioa():\n",
    "    \"\"\"\n",
    "    Face verification simulazioa\n",
    "    \"\"\"\n",
    "    # Embeddings simulatuak (128D)\n",
    "    embedding1 = np.random.randn(128)\n",
    "    embedding2_same = embedding1 + np.random.randn(128) * 0.1  # Aurpegi bera\n",
    "    embedding3_diff = np.random.randn(128)  # Aurpegi desberdina\n",
    "    \n",
    "    # Distantziak kalkulatu (Euclidean)\n",
    "    dist_same = np.linalg.norm(embedding1 - embedding2_same)\n",
    "    dist_diff = np.linalg.norm(embedding1 - embedding3_diff)\n",
    "    \n",
    "    # Threshold\n",
    "    threshold = 0.6\n",
    "    \n",
    "    print(\"üîê Face Verification Simulazioa:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Embedding 1 vs Embedding 2 (aurpegi bera):\")\n",
    "    print(f\"  Distantzia: {dist_same:.4f}\")\n",
    "    print(f\"  Berifikazio: {'‚úÖ BAI' if dist_same < threshold else '‚ùå EZ'}\")\n",
    "    print()\n",
    "    print(f\"Embedding 1 vs Embedding 3 (aurpegi desberdina):\")\n",
    "    print(f\"  Distantzia: {dist_diff:.4f}\")\n",
    "    print(f\"  Berifikazio: {'‚úÖ BAI' if dist_diff < threshold else '‚ùå EZ'}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Bistaratu\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    \n",
    "    distantziak = [dist_same, dist_diff]\n",
    "    labels = ['Aurpegi bera', 'Aurpegi desberdina']\n",
    "    colors = ['green' if d < threshold else 'red' for d in distantziak]\n",
    "    \n",
    "    bars = ax.bar(labels, distantziak, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "    ax.axhline(y=threshold, color='blue', linestyle='--', linewidth=2, label=f'Threshold ({threshold})')\n",
    "    \n",
    "    ax.set_ylabel('Distantzia', fontsize=12)\n",
    "    ax.set_title('üîê Face Verification - Distantziak', fontsize=16, fontweight='bold')\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Balioak gehitu\n",
    "    for bar, dist in zip(bars, distantziak):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "               f'{dist:.4f}',\n",
    "               ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "face_verification_simulazioa()\n",
    "print(\"\\n‚úÖ Face verification simulazioa osatuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fb9b68",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Face Identification Simulazioa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b9d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face identification adibidea\n",
    "def face_identification_simulazioa():\n",
    "    \"\"\"\n",
    "    Face identification simulazioa\n",
    "    \"\"\"\n",
    "    # Datu-basea (embeddings simulatuak)\n",
    "    database = {\n",
    "        'Mikel': np.random.randn(128),\n",
    "        'Ane': np.random.randn(128),\n",
    "        'Jon': np.random.randn(128),\n",
    "        'Leire': np.random.randn(128)\n",
    "    }\n",
    "    \n",
    "    # Aurpegi berria (Mikel-en antzekoa)\n",
    "    query_embedding = database['Mikel'] + np.random.randn(128) * 0.1\n",
    "    \n",
    "    # Distantziak kalkulatu\n",
    "    distantziak = {}\n",
    "    for izena, embedding in database.items():\n",
    "        dist = np.linalg.norm(query_embedding - embedding)\n",
    "        distantziak[izena] = dist\n",
    "    \n",
    "    # Hurbilena aurkitu\n",
    "    hurbilena = min(distantziak, key=distantziak.get)\n",
    "    dist_min = distantziak[hurbilena]\n",
    "    \n",
    "    # Threshold\n",
    "    threshold = 0.6\n",
    "    \n",
    "    print(\"üîç Face Identification Simulazioa:\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Datu-baseko distantziak:\")\n",
    "    for izena, dist in sorted(distantziak.items(), key=lambda x: x[1]):\n",
    "        print(f\"  {izena}: {dist:.4f}\")\n",
    "    print()\n",
    "    if dist_min < threshold:\n",
    "        print(f\"‚úÖ Identifikatuta: {hurbilena} (distantzia: {dist_min:.4f})\")\n",
    "    else:\n",
    "        print(f\"‚ùå Ezezaguna (distantzia minimoa: {dist_min:.4f} > threshold: {threshold})\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Bistaratu\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    \n",
    "    izenak = list(distantziak.keys())\n",
    "    dists = list(distantziak.values())\n",
    "    colors = ['lime' if d == dist_min and d < threshold else 'lightblue' for d in dists]\n",
    "    \n",
    "    bars = ax.bar(izenak, dists, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "    ax.axhline(y=threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold ({threshold})')\n",
    "    \n",
    "    ax.set_ylabel('Distantzia', fontsize=12)\n",
    "    ax.set_title('üîç Face Identification - Distantziak', fontsize=16, fontweight='bold')\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Balioak gehitu\n",
    "    for bar, dist in zip(bars, dists):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "               f'{dist:.4f}',\n",
    "               ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "face_identification_simulazioa()\n",
    "print(\"\\n‚úÖ Face identification simulazioa osatuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbfa48d",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Face Recognition Pipeline Osoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6069b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face recognition pipeline osoa\n",
    "def face_recognition_pipeline():\n",
    "    \"\"\"\n",
    "    Face recognition pipeline osoa simulatu\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Face Recognition Pipeline:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Face Detection\n",
    "    print(\"\\n1Ô∏è‚É£ Face Detection...\")\n",
    "    print(\"   ‚úÖ Aurpegia detektatuta (x=100, y=150, w=80, h=100)\")\n",
    "    print(\"   ‚úÖ Confidence: 0.98\")\n",
    "    \n",
    "    # 2. Face Alignment\n",
    "    print(\"\\n2Ô∏è‚É£ Face Alignment...\")\n",
    "    print(\"   ‚úÖ Begiak lerrokatuta\")\n",
    "    print(\"   ‚úÖ Normalizatuta (224x224)\")\n",
    "    \n",
    "    # 3. Face Encoding\n",
    "    print(\"\\n3Ô∏è‚É£ Face Encoding...\")\n",
    "    print(\"   ‚úÖ CNN eredua aplikatuta (FaceNet)\")\n",
    "    embedding = np.random.randn(128)\n",
    "    print(f\"   ‚úÖ Embedding sortuta (128D): [{embedding[0]:.3f}, {embedding[1]:.3f}, ...]\")\n",
    "    \n",
    "    # 4. Face Recognition\n",
    "    print(\"\\n4Ô∏è‚É£ Face Recognition...\")\n",
    "    print(\"   ‚úÖ Datu-basearekin konparatuta\")\n",
    "    print(\"   ‚úÖ Identifikatuta: Mikel (distantzia: 0.42)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ Pipeline osatuta!\")\n",
    "\n",
    "face_recognition_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bf8327",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Aplikazio Errealak\n",
    "\n",
    "### üè¢ Aplikazioak\n",
    "\n",
    "1. **Segurtasuna**: Sarrera-kontrola, kamera jarraipen\n",
    "2. **Mugikorrak**: Face Unlock (iPhone Face ID)\n",
    "3. **Sare sozialak**: Auto-tagging (Facebook)\n",
    "4. **Banku-sistema**: Autentifikazioa\n",
    "5. **Tailerra**: Asistentzia kontrola\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è Etikako Kontuak\n",
    "\n",
    "- **Pribatutasuna**: Datuak babestea\n",
    "- **Baimena**: Erabiltzaileen baimena behar da\n",
    "- **Bias**: Ereduak ez dira orekatsuta (arraza, generoa, adina)\n",
    "- **Transparentzia**: Erabiltzaileak jakin behar dute\n",
    "- **Erabilera**: Ez erabilera diskriminatzailerako"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0430e1ae",
   "metadata": {},
   "source": [
    "## üîü Eredu Nagusiak\n",
    "\n",
    "### üì¶ Liburutegiak\n",
    "\n",
    "1. **dlib**: HOG + CNN, face landmarks\n",
    "2. **OpenCV**: Haar Cascades, DNN module\n",
    "3. **face_recognition**: dlib-en wrapper sinplea\n",
    "4. **DeepFace**: FaceNet, VGG-Face, ArcFace, etc.\n",
    "5. **InsightFace**: State-of-the-art face recognition\n",
    "\n",
    "---\n",
    "\n",
    "### üèÜ Ereduak\n",
    "\n",
    "| Eredua | Tamaina | Zehaztasuna | Abiadura |\n",
    "|--------|---------|-------------|----------|\n",
    "| **FaceNet** | 128D | 99.63% | Motela |\n",
    "| **VGG-Face** | 4096D | 98.95% | Motela |\n",
    "| **ArcFace** | 512D | 99.83% | Ertaina |\n",
    "| **DeepFace** | 4096D | 97.35% | Motela |\n",
    "| **Dlib** | 128D | 99.38% | Azkarra |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd8e1da",
   "metadata": {},
   "source": [
    "## üìù Ondorioak\n",
    "\n",
    "### üéØ Ikasitako Kontzeptuak\n",
    "\n",
    "- **Face Detection**: Aurpegiak detektatu\n",
    "- **Face Recognition**: Aurpegiak identifikatu\n",
    "- **Face Embeddings**: 128D bektoreak\n",
    "- **Verification vs Identification**: 1:1 vs 1:N\n",
    "- **Pipeline**: Detection ‚Üí Alignment ‚Üí Encoding ‚Üí Recognition\n",
    "\n",
    "### üìä Teknikak\n",
    "\n",
    "| Teknika | Erabilera | Abantailak |\n",
    "|---------|-----------|-----------|\n",
    "| **Haar Cascades** | Legacy | Oso azkarra |\n",
    "| **HOG** | Desktop | Ona |\n",
    "| **CNN** | Produkzioa | Zehaztasun handia |\n",
    "| **FaceNet** | State-of-art | Embedding onak |\n",
    "\n",
    "### üöÄ Hurrengo Pausoak\n",
    "\n",
    "- **Praktika**: face_recognition liburutegia erabili\n",
    "- **Custom dataset**: Gure aurpegiak identifikatzeko\n",
    "- **Real-time**: Webcam-etik aurpegiak identifikatu\n",
    "- **DeepFake Detection**: Aurpegi faltsoak detektatu\n",
    "\n",
    "---\n",
    "\n",
    "**Egilea**: Mikel Aldalur Corta  \n",
    "**Data**: 2025  \n",
    "**Lizentzia**: MIT"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
