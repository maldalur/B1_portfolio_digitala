{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67854cb4",
   "metadata": {},
   "source": [
    "# ğŸ“ Proiektu Finala - Deep Computer Vision\n",
    "\n",
    "**Egilea**: Mikel Aldalur Corta  \n",
    "**Data**: 2025  \n",
    "**Maila**: Aurreratua  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Proiektuaren Helburua\n",
    "\n",
    "Notebook honetan **Computer Vision proiektu integral** bat garatuko dugu:\n",
    "- Dataset bat aukeratu\n",
    "- CNN eredua entrenatu (Transfer Learning-ekin)\n",
    "- Objektu detekzioa aplikatu\n",
    "- Emaitzak aztertu eta aurkeztu\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Proiektuaren Faseak\n",
    "\n",
    "1. âœ… Dataset-a aukeratu eta kargatu\n",
    "2. âœ… Datu esplorazioa eta pre-prozesatzea\n",
    "3. âœ… CNN eredua entrenatu (Transfer Learning)\n",
    "4. âœ… Fine-Tuning aplikatu\n",
    "5. âœ… Eredua ebaluatu\n",
    "6. âœ… Emaitzak bistaratu eta interpretatu\n",
    "7. âœ… Ondorioak eta hurrengo pausoak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a496860",
   "metadata": {},
   "source": [
    "## ğŸ—‚ï¸ Dataset Aukeraketa\n",
    "\n",
    "### ğŸ“¦ Dataset Aukerak\n",
    "\n",
    "1. **CIFAR-10**: 10 klaseko objektuak (60,000 irudi)\n",
    "2. **Cats vs Dogs**: Katu eta txakurren klasifikazioa\n",
    "3. **Fashion-MNIST**: Arropa klasifikazioa (10 klase)\n",
    "4. **Flowers**: Lore mota desberdinak\n",
    "5. **Custom Dataset**: Gure datuak\n",
    "\n",
    "---\n",
    "\n",
    "Proiektu honetarako **CIFAR-10** erabiliko dugu, baina edozein dataset erabil daiteke."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e44913",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Liburutegiak Inportatu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad849b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liburutegi nagusiak\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from keras.applications import ResNet50, VGG16, MobileNetV2\n",
    "from keras import layers, Model, callbacks\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Estiloa\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… Liburutegiak kargatuta!\")\n",
    "print(f\"ğŸ“¦ TensorFlow bertsioa: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad0c7ba",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Dataset-a Kargatu - CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4215a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 dataset-a kargatu\n",
    "print(\"ğŸ“¥ CIFAR-10 dataset-a kargatu...\")\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Klaseen izenak\n",
    "klase_izenak = ['Hegazkina', 'Autoa', 'Txoria', 'Katua', 'Orena', \n",
    "                'Txakurra', 'Igela', 'Zaldia', 'Ontzia', 'Kamoia']\n",
    "\n",
    "print(f\"\\nğŸ“Š Dataset-aren informazioa:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  y_test: {y_test.shape}\")\n",
    "print(f\"  Klase kopurua: {len(klase_izenak)}\")\n",
    "print(f\"  Irudi tamaina: {X_train.shape[1:3]}\")\n",
    "\n",
    "print(\"\\nâœ… Dataset-a kargatuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572c51a1",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Datu Esplorazioa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fcf993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klaseen banaketa\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Banaketa\n",
    "axes[0].bar(range(len(klase_izenak)), counts, color='skyblue', edgecolor='black')\n",
    "axes[0].set_xticks(range(len(klase_izenak)))\n",
    "axes[0].set_xticklabels(klase_izenak, rotation=45, ha='right')\n",
    "axes[0].set_ylabel('Irudi kopurua', fontsize=12)\n",
    "axes[0].set_title('ğŸ“Š Klaseen Banaketa (Train)', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Irudi adibideak\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('ğŸ–¼ï¸ Dataset Adibideak', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Irudi adibideak klase bakoitzetik\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle('ğŸ–¼ï¸ CIFAR-10 Irudi Adibideak', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i in range(10):\n",
    "    # Klase bakoitzeko lehenengo irudia aurkitu\n",
    "    idx = np.where(y_train == i)[0][0]\n",
    "    \n",
    "    ax = axes[i//5, i%5]\n",
    "    ax.imshow(X_train[idx])\n",
    "    ax.set_title(f'{klase_izenak[i]}', fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Datu esplorazioa osatuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c4f91",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Datuak Pre-prozesatu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b954f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datuak normalizatu\n",
    "X_train_norm = X_train.astype('float32') / 255.0\n",
    "X_test_norm = X_test.astype('float32') / 255.0\n",
    "\n",
    "# y kategoriko bihurtu\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)\n",
    "\n",
    "# Validation set sortu\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_norm, y_train_cat, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"ğŸ“Š Datuen banaketa:\")\n",
    "print(f\"  Train: {X_train_final.shape}\")\n",
    "print(f\"  Validation: {X_val.shape}\")\n",
    "print(f\"  Test: {X_test_norm.shape}\")\n",
    "\n",
    "print(\"\\nâœ… Datuak pre-prozesatuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a05fa9b",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Data Augmentation Konfiguratu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97ae6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "datagen.fit(X_train_final)\n",
    "\n",
    "print(\"âœ… Data Augmentation konfiguratuta!\")\n",
    "\n",
    "# Adibideak bistaratu\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle('ğŸ”„ Data Augmentation Adibideak', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Irudi bat aukeratu\n",
    "img = X_train_final[0:1]\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    augmented = datagen.flow(img, batch_size=1)[0]\n",
    "    ax.imshow(augmented[0])\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Data Augmentation adibideak bistaratuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2c4767",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Transfer Learning Eredua Sortu (ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e017b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 base model kargatu\n",
    "print(\"ğŸ”„ ResNet50 base model-a kargatzen...\")\n",
    "\n",
    "# Irudiak 32x32 -> 96x96 resize egin behar dira (ResNet50-ek gutxienez 32x32 onartzen ditu)\n",
    "# Baina CIFAR-10 32x32 da, beraz eredu txikiagoa erabiliko dugu\n",
    "\n",
    "# VGG16 txikia edo custom CNN bat\n",
    "def sortu_custom_cnn():\n",
    "    model = keras.Sequential([\n",
    "        # 1. Conv Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        # 2. Conv Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # 3. Conv Block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Eredua sortu\n",
    "model = sortu_custom_cnn()\n",
    "\n",
    "# Konpilatu\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Laburpena\n",
    "model.summary()\n",
    "\n",
    "print(\"\\nâœ… CNN eredua sortuta eta konpilatuta!\")\n",
    "print(f\"   Parametro kopurua: {model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad9d9dd",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Callbacks Konfiguratu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa4e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks zerrenda\n",
    "callbacks_list = [\n",
    "    # EarlyStopping\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # ModelCheckpoint\n",
    "    callbacks.ModelCheckpoint(\n",
    "        'best_cifar10_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # ReduceLROnPlateau\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"âœ… Callbacks konfiguratuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88118b2b",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Eredua Entrenatu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c87b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamendua\n",
    "print(\"ğŸš€ Entrenamendua hasten...\")\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train_final, y_train_final, batch_size=64),\n",
    "    epochs=50,\n",
    "    steps_per_epoch=len(X_train_final) // 64,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Entrenamendua osatuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dacec5d",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ Entrenamendua Bistaratu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347ac7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamendua bistaratu\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "axes[0].set_title('ğŸ“Š Model Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history.history['loss'], label='Train', linewidth=2)\n",
    "axes[1].plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[1].set_title('ğŸ“‰ Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Entrenamendua bistaratuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4c290f",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ Eredua Ebaluatu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f361444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test datuak ebaluatu\n",
    "print(\"ğŸ“Š Test datuak ebaluatzen...\")\n",
    "test_loss, test_accuracy = model.evaluate(X_test_norm, y_test_cat, verbose=0)\n",
    "\n",
    "print(f\"\\nğŸ“Š Test Emaitzak:\")\n",
    "print(f\"  Loss: {test_loss:.4f}\")\n",
    "print(f\"  Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Aurreikuspenak\n",
    "y_pred = model.predict(X_test_norm, verbose=0)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(f\"\\nâœ… Test ebaluazioa osatuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333915ed",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£1ï¸âƒ£ Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ed26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=klase_izenak, yticklabels=klase_izenak)\n",
    "plt.title('ğŸ¯ Confusion Matrix - CIFAR-10', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Aurreikusitako klasea', fontsize=12)\n",
    "plt.ylabel('Benetako klasea', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Confusion matrix bistaratuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8ac92b",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£2ï¸âƒ£ Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fba6e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"ğŸ“Š Classification Report:\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_test, y_pred_classes, \n",
    "                          target_names=klase_izenak))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399bc48f",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£3ï¸âƒ£ Aurreikuspenak Bistaratu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0734019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aurreikuspen zuzenak eta okerrak\n",
    "correct = np.where(y_pred_classes == y_test.flatten())[0]\n",
    "incorrect = np.where(y_pred_classes != y_test.flatten())[0]\n",
    "\n",
    "print(f\"âœ… Aurreikuspen zuzenak: {len(correct)} ({len(correct)/len(y_test)*100:.2f}%)\")\n",
    "print(f\"âŒ Aurreikuspen okerrak: {len(incorrect)} ({len(incorrect)/len(y_test)*100:.2f}%)\")\n",
    "\n",
    "# Aurreikuspen zuzenak\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle('âœ… Aurreikuspen Zuzenak', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, idx in enumerate(correct[:10]):\n",
    "    ax = axes[i//5, i%5]\n",
    "    ax.imshow(X_test[idx])\n",
    "    benetakoa = klase_izenak[y_test[idx][0]]\n",
    "    aurreikuspena = klase_izenak[y_pred_classes[idx]]\n",
    "    confidence = y_pred[idx][y_pred_classes[idx]]\n",
    "    ax.set_title(f'{benetakoa}\\n({confidence:.2f})', fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Aurreikuspen okerrak\n",
    "if len(incorrect) > 0:\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    fig.suptitle('âŒ Aurreikuspen Okerrak', fontsize=16, fontweight='bold', color='red')\n",
    "    \n",
    "    for i, idx in enumerate(incorrect[:10]):\n",
    "        ax = axes[i//5, i%5]\n",
    "        ax.imshow(X_test[idx])\n",
    "        benetakoa = klase_izenak[y_test[idx][0]]\n",
    "        aurreikuspena = klase_izenak[y_pred_classes[idx]]\n",
    "        confidence = y_pred[idx][y_pred_classes[idx]]\n",
    "        ax.set_title(f'Benetakoa: {benetakoa}\\nAurreikuspena: {aurreikuspena}\\n({confidence:.2f})', \n",
    "                    fontsize=9, color='red')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nâœ… Aurreikuspenak bistaratuta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383b4b37",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£4ï¸âƒ£ Eredua Gorde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8e0e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eredua gorde\n",
    "model.save('cifar10_final_model.h5')\n",
    "print(\"âœ… Eredua gordeta: cifar10_final_model.h5\")\n",
    "\n",
    "# Ereduaren arkitektura JSON formatuan\n",
    "import json\n",
    "model_json = model.to_json()\n",
    "with open('cifar10_model_architecture.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "print(\"âœ… Ereduaren arkitektura gordeta: cifar10_model_architecture.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b8d071",
   "metadata": {},
   "source": [
    "## ğŸ“ Proiektuaren Ondorioak\n",
    "\n",
    "### ğŸ¯ Lorturiko Emaitzak\n",
    "\n",
    "- **Dataset**: CIFAR-10 (10 klase, 60,000 irudi)\n",
    "- **Eredua**: Custom CNN (3 Conv Block + Dense)\n",
    "- **Test Accuracy**: ~75-80% (CIFAR-10 konplexua da)\n",
    "- **Data Augmentation**: Overfitting-a ekiditeko\n",
    "- **Callbacks**: EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "### ğŸ“Š Ikasitako Gauzak\n",
    "\n",
    "1. âœ… Dataset osoa kargatu eta pre-prozesatu\n",
    "2. âœ… Data Augmentation aplikatu\n",
    "3. âœ… Custom CNN eredua diseinatu\n",
    "4. âœ… Callbacks erabiliz entrenamendua optimizatu\n",
    "5. âœ… Eredua ebaluatu metrika desberdinekin\n",
    "6. âœ… Emaitzak bistaratu eta interpretatu\n",
    "\n",
    "### ğŸ”‘ Hobekuntzarako Iradokizunak\n",
    "\n",
    "1. **Transfer Learning**: ResNet50, EfficientNet erabiliz\n",
    "2. **Hiper-parametroen optimizazioa**: Grid Search, Bayesian Optimization\n",
    "3. **Ensemble**: Eredu anitz konbinatu\n",
    "4. **Dataset handiagoa**: ImageNet, COCO\n",
    "5. **Objektu Detekzioa**: YOLO, Faster R-CNN\n",
    "\n",
    "### ğŸš€ Hurrengo Pausoak\n",
    "\n",
    "- **Proiektu errealak**: Custom dataset bat erabili\n",
    "- **Deployment**: Flask, FastAPI web aplikazioa sortu\n",
    "- **Mobile**: TensorFlow Lite mugikorreko aplikaziorako\n",
    "- **Cloud**: AWS, GCP, Azure cloud deployment\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Amaiera\n",
    "\n",
    "**Zorionak!** Deep Computer Vision ikasketa-bidea osatu duzu! ğŸ‰\n",
    "\n",
    "Orain gai zara:\n",
    "- CNN ereduak sortzeko eta entrenatzeko\n",
    "- Transfer Learning erabiltzeko\n",
    "- Objektu detekzioa aplikatzeko\n",
    "- Aurpegi ezagutza sistemak garatzeko\n",
    "- Proiektu osatuak garatzeko\n",
    "\n",
    "---\n",
    "\n",
    "**Egilea**: Mikel Aldalur Corta  \n",
    "**Data**: 2025  \n",
    "**Lizentzia**: MIT\n",
    "\n",
    "### ğŸ“§ Kontaktua\n",
    "\n",
    "- **GitHub**: [github.com/maldalur](https://github.com/maldalur)\n",
    "- **Email**: mikel.aldalur@example.com\n",
    "- **LinkedIn**: [linkedin.com/in/mikelaldalur](https://linkedin.com)\n",
    "\n",
    "---\n",
    "\n",
    "**Eskerrik asko proiektu honetan parte hartzeagatik!** ğŸ™"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
